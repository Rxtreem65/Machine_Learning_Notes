{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the delimiter is the tab which means that the two colums are separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Restaurant_Reviews.tsv\", sep='\\t', quoting = 3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning \n",
      "\n",
      "Wow... Loved this place.\n"
     ]
    }
   ],
   "source": [
    "# removing the unnecessary values other than a-z and A-Z characters\n",
    "import re\n",
    "print(\"Before cleaning \\n\")\n",
    "print(df['Review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cleaning\n",
      "\n",
      "Wow    Loved this place \n"
     ]
    }
   ],
   "source": [
    "check = re.sub('[^a-zA-Z]',\n",
    "               ' ',\n",
    "              df['Review'][0])\n",
    "# the hat insures that only the mentioned values are not removed check what happens without ^\n",
    "print(\"after cleaning\\n\")\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow    loved this place \n"
     ]
    }
   ],
   "source": [
    "# converting the entire string in lower case\n",
    "check = check.lower()\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " stopwords:\n",
    " stop words are any words in a stop list which are fitted out before or after processing of natural language data. \n",
    " \n",
    "there is no signle universal list of stop words used by all natural language processing tools, nor any agreed upon rules for identification stop words, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['wow', 'loved', 'this', 'place']\n",
      "\n",
      " ['wow', 'loved', 'place']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/riyaparikh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# removing the non-significant words like umm, the, etc may it be articles etc.\n",
    "import nltk\n",
    "\n",
    "# downloading the stopwords\n",
    "# stop words is a collection of irrelevant words in review\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "check = check.split()\n",
    "print(\"\\n\", check)\n",
    "\n",
    "check = [word for word in check if not word in set(stopwords.words('english'))]\n",
    "print('\\n',check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['wow', 'love', 'place']\n"
     ]
    }
   ],
   "source": [
    "# stemming the data\n",
    "# stemming is the process of identifying the root word from a given word eg. love is the root of loved, lovable etc.\n",
    "\"\"\"\n",
    "the porter stemming algorithm (or 'Poter stemmer') is a process for removing the commoner morphological and inflecional endings from\n",
    "words in english. Its main use is as part of a term normalisation process that is usally done when setting up Information Retrival system.\n",
    "\"\"\"\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "check = [ps.stem(word) for word in check if not word in set(stopwords.words('english'))]\n",
    "print('\\n', check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow love place\n"
     ]
    }
   ],
   "source": [
    "# joining back the phrase together\n",
    "check = ' '.join(check)\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus:\n",
    "it is a collection of common words in the literature not necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stepwords: Package 'stepwords' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "import re # this library is used for cleaning\n",
    "import nltk # will help to download ensemble of stop words (words not relevant for prediction like the a na etc)\n",
    "nltk.download('stepwords')\n",
    "from nltk.corpus import stopwords # used to import the stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# steming is used to get only the root of the word which is enough to understand what the word means\n",
    "# loved to love hated to hate etc. removes conjuctions just keeping the verbs and adjectives\n",
    "\n",
    "corpus = [] # this list will contain all the different reviews after it is cleaned\n",
    "for i in range(0,1000): # since the data contains 1000 reviews\n",
    "    # the sub function is used not to remove the desired contents in the below case we remove everything but the letters a-z and A-Z\n",
    "    \n",
    "    review = re.sub('[^a-zA-Z]', ' ',\n",
    "                   df['Review'][i]) # removing punctuation and replacing them with a space\n",
    "    review = review.lower() #transforming all the capital letters into lower case \n",
    "    review = review.split() #slpitting the elements into words \n",
    "\n",
    "ps = PorterStemmer() #porter stemming object creation \n",
    "all_stopwords = stopwords.words('english') \n",
    "all_stopwords.remove('not') \n",
    "review = [ps.stem(word) for word in review if not word in set()] \n",
    "review = ' '.join(review) #so that we don't end up with a single word \n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
